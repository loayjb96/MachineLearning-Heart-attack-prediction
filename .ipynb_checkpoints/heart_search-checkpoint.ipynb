{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "heart= pd.read_csv('heart.csv')\n",
    "print(heart.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our goal is to try understand the data we got lets start \n",
    "# here we can see the info of each attribute  in the heart dataframe  as you can see it is not null \n",
    "heart.info()\n",
    "#we want to know in each coll or\"attr\" what are the distnguish value we have the counter of differ value \n",
    "print(heart.nunique())\n",
    "''' as you  '''\n",
    "#let us rename the colm we  have to be more understandable \n",
    "heart.columns = ['Age', 'Gender', 'ChestPain', 'RestingBloodPressure', 'Cholestrol', 'FastingBloodSugar', 'RestingECG', 'MaxHeartRateAchivied',\n",
    "       'ExerciseIndusedAngina', 'Oldpeak', 'Slope', 'MajorVessels', 'Thalassemia', 'Target']\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[]\n",
    "fig=plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in heart:\n",
    "    ax=sns.countplot(x=i,data=heart)\n",
    "    arr.append(ax)\n",
    "    fig=plt.figure(figsize=(4, 4))\n",
    "#     plt.title(i)\n",
    "\n",
    "    \n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import itertools\n",
    "# columns=heart.columns[:14]\n",
    "# plt.subplots(figsize=(28,25))\n",
    "# length=len(columns)\n",
    "# for i,j in itertools.zip_longest(columns,range(length)):\n",
    "#     plt.subplot((length/2),3,j+1)\n",
    "#     plt.subplots_adjust(wspace=0.2,hspace=0.5)\n",
    "#     heart[i].hist(bins=20,edgecolor='black')\n",
    "#     plt.title(i)\n",
    "# # plt.clf()\n",
    "\n",
    "# plt.savefig('new_plot/count')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"hssi\")\n",
    "# columns=heart.columns[:14]\n",
    "# plt.subplots(figsize=(28,25))\n",
    "# length=len(columns)\n",
    "# for i,j in itertools.zip_longest(columns,range(length)):\n",
    "#     plt.subplot((length/2),3,j+1)\n",
    "#     plt.subplots_adjust(wspace=0.2,hspace=0.5)\n",
    "#     ax=sns.swarmplot(heart[i] )\n",
    "# #     plt.plot(ax)\n",
    "# #     heart[i].hist(bins=20,edgecolor='black')\n",
    "#     plt.title(i)\n",
    "# # plt.clf()\n",
    "\n",
    "# plt.savefig('new_plot/ss')\n",
    "\n",
    "# plt.show()\n",
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### lets know split the data we have in order to start the learning procsses \n",
    "heart.head()\n",
    "X_data = heart.drop(columns=['Target'], axis=1)\n",
    "Y = heart['Target']\n",
    "\n",
    "#normalize the data\n",
    "Y = ((Y - np.min(Y))/ (np.max(Y) - np.min(Y))).values\n",
    "X = ((X_data - np.min(X_data)) / (np.max(X_data) - np.min(X_data))).values\n",
    "# we want here to seprate the data for the learning procsses testdata=30% train 70 %\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size = 0.3,random_state=42)\n",
    "print(\" yoi \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let know use two type of classfication algortimm i will first use logstic regression \n",
    "logisticRegr=LogisticRegression()\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "pred = logisticRegr.predict(x_test)\n",
    "score = logisticRegr.score(x_test, y_test)\n",
    "print(\"score is\",score)\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "cmlogstic=confusion_matrix(y_test,pred)\n",
    "\n",
    "#####################################3\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt   \n",
    "# def result_score_of_model(model,ytest):\n",
    "#     score=model.score\n",
    "    \n",
    "def plot_heat(cm,title):\n",
    "    \n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(['business', 'health']); ax.yaxis.set_ticklabels(['health', 'business']);\n",
    "    plt.savefig('new_plot/'+title)\n",
    "    plt.show()\n",
    "plot_heat(cm,'logsticheat')\n",
    "fa_logstic=f1_score(y_test, pred, average='weighted')\n",
    "print(fa_logstic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# usin svm learning algotrim \n",
    "types=['rbf','linear']\n",
    "for i in types:\n",
    "    model=svm.SVC(kernel=i)\n",
    "    model.fit(x_train,y_train)\n",
    "#     predsvm=mo.predict(x_test)\n",
    "    svm_prediction=model.predict(x_test)\n",
    "    cmsvm=confusion_matrix(y_test,svm_prediction)\n",
    "    plot_heat(cmsvm,i+' svm')\n",
    "    \n",
    "    print(len(svm_prediction))\n",
    "    print('Accuracy for SVM kernel=',i,'is',metrics.accuracy_score(svm_prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
